
@article{kypraiou_what_2021,
	title = {What is {Fairness}?},
	issn = {,},
	url = {https://feministai.pubpub.org/pub/what-is-fairness-/release/1},
	abstract = {Many efforts have been made to try to  ‘debias’ the data and create a ‘fair’ model.  But what is fairness? And how can this translate to machine learning?},
	language = {en},
	urldate = {2022-10-06},
	author = {Kypraiou, Sofia},
	month = sep,
	year = {2021},
	note = {Publisher: PubPub},
	file = {Full Text PDF:/Users/rosecporta/Zotero/storage/L9V6Z2JI/Kypraiou - 2021 - What is Fairness.pdf:application/pdf;Snapshot:/Users/rosecporta/Zotero/storage/ZGMYGUHU/1.html:text/html},
}

@misc{barocas_fairness_nodate,
	title = {Fairness and machine learning},
	url = {https://fairmlbook.org/},
	urldate = {2022-10-06},
	author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
	file = {Fairness and machine learning:/Users/rosecporta/Zotero/storage/CKPTZN24/fairmlbook.org.html:text/html},
}

@misc{gebru_datasheets_2021,
	title = {Datasheets for {Datasets}},
	url = {http://arxiv.org/abs/1803.09010},
	doi = {10.48550/arXiv.1803.09010},
	abstract = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
	urldate = {2022-10-06},
	publisher = {arXiv},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daumé III, Hal and Crawford, Kate},
	month = dec,
	year = {2021},
	note = {arXiv:1803.09010 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases, Computer Science - Machine Learning},
	annote = {Comment: Published in CACM in December, 2021},
	file = {arXiv Fulltext PDF:/Users/rosecporta/Zotero/storage/SNPIDA6P/Gebru et al. - 2021 - Datasheets for Datasets.pdf:application/pdf;arXiv.org Snapshot:/Users/rosecporta/Zotero/storage/JH453QWU/1803.html:text/html},
}

@article{knight_automated_2020,
	title = {Automated {Decision}-making and {Judicial} {Review}},
	copyright = {© 2020 Informa UK Limited, trading as Taylor \& Francis Group},
	issn = {1085-4681},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10854681.2020.1732740},
	abstract = {Published in Judicial Review (Vol. 25, No. 1, 2020)},
	language = {en},
	urldate = {2022-10-06},
	journal = {Judicial Review},
	author = {Knight, Christopher},
	month = mar,
	year = {2020},
	note = {Publisher: Routledge},
	file = {Snapshot:/Users/rosecporta/Zotero/storage/WQ8H4FTJ/10854681.2020.html:text/html},
}

@article{navarro2021risk,
  title={Risk of bias in studies on prediction models developed using supervised machine learning techniques: systematic review},
  author={Navarro, Constanza L Andaur and Damen, Johanna AA and Takada, Toshihiko and Nijman, Steven WJ and Dhiman, Paula and Ma, Jie and Collins, Gary S and Bajpai, Ram and Riley, Richard D and Moons, Karel GM and others},
  journal={bmj},
  volume={375},
  year={2021},
  publisher={British Medical Journal Publishing Group}
}

@article{hellstrom2020bias,
  title={Bias in Machine Learning--What is it Good for?},
  author={Hellstr{\"o}m, Thomas and Dignum, Virginia and Bensch, Suna},
  journal={arXiv preprint arXiv:2004.00686},
  year={2020}
}

@inproceedings{green2018myth,
  title={The myth in the methodology: Towards a recontextualization of fairness in machine learning},
  author={Green, Ben and Hu, Lily},
  booktitle={Proceedings of the machine learning: the debates workshop},
  year={2018}
}

@article{kleinberg2016inherent,
  title={Inherent trade-offs in the fair determination of risk scores},
  author={Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  journal={arXiv preprint arXiv:1609.05807},
  year={2016}
}

@article{deho2022existing,
  title={How do the existing fairness metrics and unfairness mitigation algorithms contribute to ethical learning analytics?},
  author={Deho, Oscar Blessed and Zhan, Chen and Li, Jiuyong and Liu, Jixue and Liu, Lin and Duy Le, Thuc},
  journal={British Journal of Educational Technology},
  year={2022},
  publisher={Wiley Online Library}
}

@article{kim2022information,
  title={An Information Theoretic Approach to Reducing Algorithmic Bias for Machine Learning},
  author={Kim, Jin-Young and Cho, Sung-Bae},
  journal={Neurocomputing},
  year={2022},
  publisher={Elsevier}
}

@article{anahideh2022fair,
  title={Fair active learning},
  author={Anahideh, Hadis and Asudeh, Abolfazl and Thirumuruganathan, Saravanan},
  journal={Expert Systems with Applications},
  volume={199},
  pages={116981},
  year={2022},
  publisher={Elsevier}
}
@inproceedings{binns2020apparent,
  title={On the apparent conflict between individual and group fairness},
  author={Binns, Reuben},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={514--524},
  year={2020}
}
@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{caton2020fairness,
  title={Fairness in machine learning: A survey},
  author={Caton, Simon and Haas, Christian},
  journal={arXiv preprint arXiv:2010.04053},
  year={2020}
}
@inproceedings{juba2019precision,
  title={Precision-recall versus accuracy and the role of large data sets},
  author={Juba, Brendan and Le, Hai S},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={4039--4048},
  year={2019}
}
@inproceedings{gupta2021recall,
  title={Recall-based Machine Learning approach for early detection of Cervical Cancer},
  author={Gupta, Apoorva and Anand, Ashutosh and Hasija, Yasha},
  booktitle={2021 6th International Conference for Convergence in Technology (I2CT)},
  pages={1--5},
  year={2021},
  organization={IEEE}
}
@article{zhou2022bias,
  title={Bias, Fairness and Accountability with Artificial Intelligence and Machine Learning Algorithms},
  author={Zhou, Nengfeng and Zhang, Zach and Nair, Vijayan N and Singhal, Harsh and Chen, Jie},
  journal={International Statistical Review},
  year={2022},
  publisher={Wiley Online Library}
}
@inproceedings{celis2019classification,
  title={Classification with fairness constraints: A meta-algorithm with provable guarantees},
  author={Celis, L Elisa and Huang, Lingxiao and Keswani, Vijay and Vishnoi, Nisheeth K},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={319--328},
  year={2019}
}
@inproceedings{agarwal2018reductions,
  title={A reductions approach to fair classification},
  author={Agarwal, Alekh and Beygelzimer, Alina and Dud{\'\i}k, Miroslav and Langford, John and Wallach, Hanna},
  booktitle={International Conference on Machine Learning},
  pages={60--69},
  year={2018},
  organization={PMLR}
}
@inproceedings{agarwal2019fair,
  title={Fair regression: Quantitative definitions and reduction-based algorithms},
  author={Agarwal, Alekh and Dud{\'\i}k, Miroslav and Wu, Zhiwei Steven},
  booktitle={International Conference on Machine Learning},
  pages={120--129},
  year={2019},
  organization={PMLR}
}
@article{pleiss2017fairness,
  title={On fairness and calibration},
  author={Pleiss, Geoff and Raghavan, Manish and Wu, Felix and Kleinberg, Jon and Weinberger, Kilian Q},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{kamiran2012decision,
  title={Decision theory for discrimination-aware classification},
  author={Kamiran, Faisal and Karim, Asim and Zhang, Xiangliang},
  booktitle={2012 IEEE 12th International Conference on Data Mining},
  pages={924--929},
  year={2012},
  organization={IEEE}
}
@article{kamiran2012data,
  title={Data preprocessing techniques for classification without discrimination},
  author={Kamiran, Faisal and Calders, Toon},
  journal={Knowledge and information systems},
  volume={33},
  number={1},
  pages={1--33},
  year={2012},
  publisher={Springer}
}
@article{wachter2021fairness,
  title={Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and AI},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Computer Law \& Security Review},
  volume={41},
  pages={105567},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{speicher2018unified,
  title={A unified approach to quantifying algorithmic unfairness: Measuring individual \&group unfairness via inequality indices},
  author={Speicher, Till and Heidari, Hoda and Grgic-Hlaca, Nina and Gummadi, Krishna P and Singla, Adish and Weller, Adrian and Zafar, Muhammad Bilal},
  booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={2239--2248},
  year={2018}
}

@inproceedings{menon2018cost,
  title={The cost of fairness in binary classification},
  author={Menon, Aditya Krishna and Williamson, Robert C},
  booktitle={Conference on Fairness, Accountability and Transparency},
  pages={107--118},
  year={2018},
  organization={PMLR}
}

@article{zliobaite2015relation,
  title={On the relation between accuracy and fairness in binary classification},
  author={Zliobaite, Indre},
  journal={arXiv preprint arXiv:1505.05723},
  year={2015}
}

@misc{goodman_2022, title={Why Amazon's Automated Hiring Tool discriminated against Women: News \& Commentary}, url={https://www.aclu.org/news/womens-rights/why-amazons-automated-hiring-tool-discriminated-against}, journal={American Civil Liberties Union}, publisher={American Civil Liberties Union}, author={Goodman, Rachel}, year={2022}, month={Sep}}

@article{nguyen2021influence,
  title={Influence of data splitting on performance of machine learning models in prediction of shear strength of soil},
  author={Nguyen, Quang Hung and Ly, Hai-Bang and Ho, Lanh Si and Al-Ansari, Nadhir and Le, Hiep Van and Tran, Van Quan and Prakash, Indra and Pham, Binh Thai},
  journal={Mathematical Problems in Engineering},
  volume={2021},
  year={2021},
  publisher={Hindawi}
}

