
@article{kypraiou_what_2021,
	title = {What is {Fairness}?},
	issn = {,},
	url = {https://feministai.pubpub.org/pub/what-is-fairness-/release/1},
	abstract = {Many efforts have been made to try to  ‘debias’ the data and create a ‘fair’ model.  But what is fairness? And how can this translate to machine learning?},
	language = {en},
	urldate = {2022-10-06},
	author = {Kypraiou, Sofia},
	month = sep,
	year = {2021},
	note = {Publisher: PubPub},
	file = {Full Text PDF:/Users/rosecporta/Zotero/storage/L9V6Z2JI/Kypraiou - 2021 - What is Fairness.pdf:application/pdf;Snapshot:/Users/rosecporta/Zotero/storage/ZGMYGUHU/1.html:text/html},
}

@misc{barocas_fairness_nodate,
	title = {Fairness and machine learning},
	url = {https://fairmlbook.org/},
	urldate = {2022-10-06},
	author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
	file = {Fairness and machine learning:/Users/rosecporta/Zotero/storage/CKPTZN24/fairmlbook.org.html:text/html},
}

@misc{gebru_datasheets_2021,
	title = {Datasheets for {Datasets}},
	url = {http://arxiv.org/abs/1803.09010},
	doi = {10.48550/arXiv.1803.09010},
	abstract = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
	urldate = {2022-10-06},
	publisher = {arXiv},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daumé III, Hal and Crawford, Kate},
	month = dec,
	year = {2021},
	note = {arXiv:1803.09010 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases, Computer Science - Machine Learning},
	annote = {Comment: Published in CACM in December, 2021},
	file = {arXiv Fulltext PDF:/Users/rosecporta/Zotero/storage/SNPIDA6P/Gebru et al. - 2021 - Datasheets for Datasets.pdf:application/pdf;arXiv.org Snapshot:/Users/rosecporta/Zotero/storage/JH453QWU/1803.html:text/html},
}

@article{knight_automated_2020,
	title = {Automated {Decision}-making and {Judicial} {Review}},
	copyright = {© 2020 Informa UK Limited, trading as Taylor \& Francis Group},
	issn = {1085-4681},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10854681.2020.1732740},
	abstract = {Published in Judicial Review (Vol. 25, No. 1, 2020)},
	language = {en},
	urldate = {2022-10-06},
	journal = {Judicial Review},
	author = {Knight, Christopher},
	month = mar,
	year = {2020},
	note = {Publisher: Routledge},
	file = {Snapshot:/Users/rosecporta/Zotero/storage/WQ8H4FTJ/10854681.2020.html:text/html},
}

@article{navarro2021risk,
  title={Risk of bias in studies on prediction models developed using supervised machine learning techniques: systematic review},
  author={Navarro, Constanza L Andaur and Damen, Johanna AA and Takada, Toshihiko and Nijman, Steven WJ and Dhiman, Paula and Ma, Jie and Collins, Gary S and Bajpai, Ram and Riley, Richard D and Moons, Karel GM and others},
  journal={bmj},
  volume={375},
  year={2021},
  publisher={British Medical Journal Publishing Group}
}

@article{hellstrom2020bias,
  title={Bias in Machine Learning--What is it Good for?},
  author={Hellstr{\"o}m, Thomas and Dignum, Virginia and Bensch, Suna},
  journal={arXiv preprint arXiv:2004.00686},
  year={2020}
}

@inproceedings{green2018myth,
  title={The myth in the methodology: Towards a recontextualization of fairness in machine learning},
  author={Green, Ben and Hu, Lily},
  booktitle={Proceedings of the machine learning: the debates workshop},
  year={2018}
}

@article{kleinberg2016inherent,
  title={Inherent trade-offs in the fair determination of risk scores},
  author={Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  journal={arXiv preprint arXiv:1609.05807},
  year={2016}
}

@article{deho2022existing,
  title={How do the existing fairness metrics and unfairness mitigation algorithms contribute to ethical learning analytics?},
  author={Deho, Oscar Blessed and Zhan, Chen and Li, Jiuyong and Liu, Jixue and Liu, Lin and Duy Le, Thuc},
  journal={British Journal of Educational Technology},
  year={2022},
  publisher={Wiley Online Library}
}

@article{kim2022information,
  title={An Information Theoretic Approach to Reducing Algorithmic Bias for Machine Learning},
  author={Kim, Jin-Young and Cho, Sung-Bae},
  journal={Neurocomputing},
  year={2022},
  publisher={Elsevier}
}

@article{anahideh2022fair,
  title={Fair active learning},
  author={Anahideh, Hadis and Asudeh, Abolfazl and Thirumuruganathan, Saravanan},
  journal={Expert Systems with Applications},
  volume={199},
  pages={116981},
  year={2022},
  publisher={Elsevier}
}
